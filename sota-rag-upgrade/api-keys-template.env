# SOTA RAG API Keys Configuration Template
# Copy these lines to your .env file and fill in your actual API keys

# =============================================================================
# PHASE 1: EXTERNAL API CONFIGURATION
# =============================================================================

# OpenAI Configuration
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-openai-key-here

# Mistral Configuration  
# Get your API key from: https://console.mistral.ai/
MISTRAL_API_KEY=your-mistral-key-here

# Cohere Configuration
# Get your API key from: https://dashboard.cohere.ai/api-keys
COHERE_API_KEY=your-cohere-key-here

# Zep Configuration (Optional - for long-term memory)
# Get your API key from: https://www.getzep.com/
# Free tier: 2.6MB data, 1,000 messages, 2 projects, 300 req/min
ZEP_API_KEY=your-zep-key-here
ZEP_PROJECT_ID=your-zep-project-id

# LightRAG Server (Optional - for GraphRAG)
# This can be a cloud service or local LightRAG instance
LIGHTRAG_SERVER_URL=https://your-lightrag-server.com

# =============================================================================
# GOOGLE DRIVE INTEGRATION (Optional)
# =============================================================================

# Google Drive API (for document ingestion)
# Set up OAuth2 credentials in Google Cloud Console
GOOGLE_DRIVE_CLIENT_ID=your-client-id
GOOGLE_DRIVE_CLIENT_SECRET=your-client-secret

# =============================================================================
# ADDITIONAL SERVICE CONFIGURATIONS
# =============================================================================

# Firecrawl (for web scraping)
FIRECRAWL_API_KEY=your-firecrawl-key

# WebSearch API (for real-time information)
WEBSEARCH_API_KEY=your-websearch-key

# =============================================================================
# PHASE 2: LOCAL ALTERNATIVES CONFIGURATION
# =============================================================================

# When migrating to local-only deployment, these settings control local services

# Local LLM Configuration
LOCAL_LLM_MODEL=qwen3:8b-q4_K_M
LOCAL_EMBEDDING_MODEL=nomic-embed-text

# Local OCR Service (replace Mistral)
LOCAL_OCR_SERVICE=http://tesseract-ocr:8080
# or
LOCAL_OCR_SERVICE=http://paddle-ocr:8080

# Local Reranking Service (replace Cohere)
LOCAL_RERANK_SERVICE=http://local-reranker:8080
LOCAL_RERANK_MODEL=BAAI/bge-reranker-base

# Local Knowledge Graph (replace LightRAG cloud)
LOCAL_LIGHTRAG_SERVICE=http://local-lightrag:8080

# =============================================================================
# FEATURE FLAGS
# =============================================================================

# Enable/disable SOTA RAG features
ENABLE_LIGHTRAG=false
ENABLE_MULTIMODAL=false  
ENABLE_CONTEXTUAL=true
ENABLE_LONGTERM_MEMORY=false
ENABLE_HYBRID_SEARCH=true
ENABLE_RERANKING=true

# =============================================================================
# RATE LIMITING & PERFORMANCE
# =============================================================================

# API rate limits (requests per minute)
OPENAI_RPM_LIMIT=3500
MISTRAL_RPM_LIMIT=1000
COHERE_RPM_LIMIT=1000
ZEP_RPM_LIMIT=300

# Performance tuning
MAX_CHUNK_SIZE=1000
CHUNK_OVERLAP=200
VECTOR_SEARCH_LIMIT=30
HYBRID_SEARCH_LIMIT=50
RERANK_TOP_N=10

# Memory management
MAX_CONTEXT_TOKENS=16000
MAX_DOCUMENT_SIZE_MB=50
MAX_BATCH_SIZE=50

# =============================================================================
# DEVELOPMENT & DEBUGGING
# =============================================================================

# Debug logging
SOTA_RAG_DEBUG=false
LOG_LEVEL=info

# Development overrides
DEV_MODE=false
SKIP_RATE_LIMITS=false
USE_MOCK_APIs=false

# =============================================================================
# USAGE NOTES
# =============================================================================

# 1. For Phase 1 deployment, fill in the API keys section
# 2. For Phase 2 deployment, configure local services section  
# 3. Adjust feature flags based on your requirements
# 4. Monitor rate limits to avoid API quota issues
# 5. Use debug mode for troubleshooting workflow issues

# Example minimal Phase 1 configuration:
# OPENAI_API_KEY=sk-...
# ENABLE_CONTEXTUAL=true
# ENABLE_HYBRID_SEARCH=true

# Example minimal Phase 2 configuration:  
# LOCAL_LLM_MODEL=qwen3:8b-q4_K_M
# LOCAL_EMBEDDING_MODEL=nomic-embed-text
# ENABLE_CONTEXTUAL=true
# ENABLE_HYBRID_SEARCH=true
